{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Training Script for DVC using the IRIS CLassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Problem Statement\n",
    "\n",
    "Incorporating DVC into the week 1 iris pipeline; this version of the notebook does not include direct to gcs bucket commands and instead uses dvc to version track and push into gcs remotely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb",
    "tags": []
   },
   "source": [
    "## Setting Up the configurations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4464,
     "status": "ok",
     "timestamp": 1752137477124,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "1fd00fa70a2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137480955,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "set_project_id",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"gentle-presence-472611-u8\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137488631,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "bucket",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://mlops-course-gentle-presence-472611-u8-v4-unique-week1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2srkkUb6gOL7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://mlops-course-gentle-presence-472611-u8-v4-unique-week1/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'mlops-course-gentle-presence-472611-u8-v4-unique-week1' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3330b4f12a0d",
    "tags": []
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e088ea8cd4a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3938f6d37a1",
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qvqSD5MDgOL8",
    "outputId": "45047f0d-064c-4bcc-9c6b-bde3ea150340",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "data_v1 = pd.read_csv(\"data/v1_data.csv\")\n",
    "data_v2 = pd.read_csv(\"data/v2_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(version, data):\n",
    "    train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)\n",
    "    X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_train = train.species\n",
    "    X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_test = test.species\n",
    "    mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "    mod_dt.fit(X_train,y_train)\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prediction=mod_dt.predict(X_test)\n",
    "    out_path = f\"outputs/outputs_{version}_{timestamp}.csv\"\n",
    "    pd.DataFrame({f\"predicted_{version}\": prediction}).to_csv(out_path, index=False)\n",
    "    print('The accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    OUTPUT_FOLDER = f\"artifacts/model_{version}\"\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "    joblib.dump(mod_dt, f\"{OUTPUT_FOLDER}/model_{timestamp}.joblib\")\n",
    "    print(\"Model saved to artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree is 0.951\n",
      "Model saved to artifacts\n"
     ]
    }
   ],
   "source": [
    "train(\"v1\",data_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"v2\",data_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "### Track model with dvc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the output files using dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
